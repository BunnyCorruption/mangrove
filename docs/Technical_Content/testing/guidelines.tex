\subsubsection{Guidelines}
Testing is an important part of any project. Traditionally tests are conducted manually via the developers themselves. Trying out different inputs and manually trying to break their code. While this method is tried and true for most computer science students, automated testing is needed to truly create a robust product. Automating our testing will maximizes the efficiency of our time. Allowing for more time to be focused on creating more features, rather than trying to break them. Especially with our product, since it focuses on a large amount data; ensuring that there are no bugs is a priority. The last thing we want is for a researcher to be weary of using our product in fear that he will achieve faulty results due to problems with the program. Creating a robust product with a high fault tolerance is on the forefront of our priorities.\par
Automation of testing can increase the resilience of a product but only if done correctly. Thus, a best practice of automated testing must be established. If these rules are followed then testing will be a blessing rather than a burden. The rules are as follows:

\paragraph{Not Everything Can be Automated} \mbox{}\\[\paragraphheaderspace]
Not everything can be automated, or rather, nothing can be automated easily enough to warrant its automation. As with any script, automating testing takes time. The more complex the test case, the more time it will take to develop a script that can successfully and efficiently ensure a program is working as expected. A good benchmark in deciding whether or not a test is worth automating is to determine how many times a task is repeated and seeing how similar each repeated task actually is. Tasks that are very similar and are repeated hundreds of times should be automated without a second thought. On the other hand, if a task is very variable and must be checked with more than a small set of test cases, then a human candidate might end up being better than a script. Some other things to consider when deciding whether or not to automate include:
\begin{itemize}
  \item \textit{Prone to human error} --- If a test is difficult for a human to construct then it may be better to write a script for it.
  \item \textit{Requires multiple sets} --- If a test requires a human to access multiple data sets across different platforms it may be easier to set up a script.
  \item \textit{High Risk} --- If a test is crucial to system performance, it may be a good idea to write a script that makes sure the section of code being tested works without a doubt.
\end{itemize}

\paragraph{Test Early and Test Often} \mbox{}\\[\paragraphheaderspace]
Ideally, testing should start as soon as the first section of code has been written. Unit tests can be conducted as soon as the first logical chunk as been made. Integration testing can be conducted as soon as more than a single section of the system is functional. Data testing can be conducted as soon as a full path for data is established. As soon as a type of test is feasible to be conducted, it should be done. This kind of mindset will ensure that most bugs are caught early and often. Not only will this make a more robust product, but it will save time in the long run of production. This results from the idea that, in most projects, it is usually the base off of which everything runs that is written first. If this is the case, then a bug created early on in a project will halt development for everything written on top of it.\par
Beyond testing as soon as possible, testing should be done every time a change is made to the way the code functions. This does not mean that every superficial change should be checked, since testing after trivial changes would be much too redundant and would slow down development. However, every time something significant changes in way in which the code functions, it should be tested. This will ensure that the vast majority of bugs will be discovered quickly, allowing us to pinpoint exactly where the bugs are happening and avoiding complex combinations of bugs to form.

\paragraph{Select the Right Automated Testing Tools} \mbox{}\\[\paragraphheaderspace]
Selecting the proper tools for a system is crucial in developing efficient solutions to automated testing. Without the proper tooling, creating an automated testing system can become an uphill battle that any development team could easily end up losing, rather than saving time. We considered the following when selecting our tools for testing the software:
\begin{itemize}
  \item \textit{The tool must support your platform} --- We decided to go with Spectron because it was specifically made to be used with our Electron front end. This will make it easier to test cases that will only occur in our Electron app.
  \item \textit{Simplicity in documentation} --- Our team consists of different levels of skill in terms of scripting. Thus, we decided to go with tools that are known to have good documentation. This way, those without as much experience in testing larger applications can learn quickly and start developing scripts for their sections of the code.
  \item \textit{Flexible Tests} --- When choosing a tool, we decided to go only with those that allowed us to make flexible tests. For example, Spectron scripts are not only resilient to changes in UI but can also be reused across multiple sections of the system
\end{itemize}

\paragraph{Create Good Test Data} \mbox{}\\[\paragraphheaderspace]
Data for test cases should cover all kinds of possibilities for the code being tested, preferably in the most efficient way possible. Rather than create an extensive list of all possible inputs, it\textquotesingle s best to create sets of data that test all edge cases, as well as any other special cases that may cause problems with the code. Along with constructing good test data, it can be useful to construct external file sheets. By using external file sheets, we will be able to reuse test scripts over several sections of similar code. This is because, as opposed to hard coded data, having external data allows us to easily change what is being input to our scripts, allowing us to quickly create new test cases with appropriate data.\par
We will also be using a mixture of auto-generated and specially constructed data. The auto-generated data will be used when a vast set of data is needed to test the functionality of a code section. Data files provided to us by our sponsor will be used when specific data sets are needed. This will make sure we have a good mixture of random data and real world data to test our product.

\paragraph{Make Robust Testing Scripts} \mbox{}\\[\paragraphheaderspace]
When creating our scripts, we will use configuration files. Doing so will allow us to reuse our scripts through multiple design iterations. These configuration files will contain variables within the code. These variables will be variable names, positions of elements in the UI, and any other dynamic elements that we think will need to be changed.
